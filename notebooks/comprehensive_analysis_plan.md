# 🎯 アイドル・グループ・ファンダム包括的比較分析計画書

## 📊 エグゼクティブサマリー
本計画は、`yoake-dev-analysis.dev_yoake_posts.*`データセット内の全テーブルを対象に、アイドル個人、グループ、ファンダムの特性を多角的に分析する包括的な分析フレームワークです。

---

## 1. データソース構造

### 1.1 データセット概要
- **プロジェクト**: yoake-dev-analysis
- **データセット**: dev_yoake_posts
- **期間**: 2025年10月～11月（約1ヶ月間）
- **データ規模**: 各テーブル10万件以上

### 1.2 テーブル分類

#### グループテーブル（抽象的な名前）
- FRUITS_ZIPPER（フルーツジッパー）
- CUTIE STREET
- CANDY TUNE
- =Love
- 乃木坂46
- 櫻坂46
- 日向坂46
- 推しの子関連グループ

#### 個人テーブル（グループメンバー）
##### FRUITS ZIPPERメンバー
- 櫻井優衣
- 月足天音
- 仲川瑠夏
- 松本かれん
- 早瀬ノエル
- 真中まな
- 鎮西寿々歌

##### その他グループメンバー
- 各グループの個人メンバーテーブル

---

## 2. 分析階層定義

### 2.1 個人レベル（タレント単位）
```
分析単位: 各個人テーブル
主要指標:
- 個人への言及数
- 個人特有のキーワード
- エンゲージメント率
- ファン層の特徴
```

### 2.2 グループレベル（グループ単位）
```
分析単位: グループテーブル
主要指標:
- グループ全体への言及
- グループ特有の話題・イベント
- グループファンの行動パターン
- メンバー間の相対的人気
```

### 2.3 ファンダムレベル（コミュニティ単位）
```
分析単位: ユーザー軸での集計
主要指標:
- ファンダム規模
- コミュニティ活性度
- ファンダム文化・用語
- クロスファンダム率
```

---

## 3. ユーザーセグメント定義

### 3.1 コア層（ロイヤルカスタマー）
```python
# コア層判定基準（2つ以上該当）
1. 高頻度投稿層
   - 月間投稿数が上位10%以内
   - または週5日以上投稿

2. 高エンゲージメント獲得層
   - 平均いいね数が上位10%以内
   - または平均RT数が上位10%以内

3. 継続投稿層
   - 分析期間の80%以上の日数で投稿
   - または30日連続投稿達成

4. マルチエンゲージメント層
   - いいね、RT、引用、リプライを全て頻繁に実施
   - エンゲージメント多様性スコアが上位20%
```

### 3.2 インフルエンサー層
```python
# インフルエンサー判定基準（2つ以上該当）
1. フォロワー規模
   - フォロワー数1,000人以上
   - またはフォロワー/フォロー比が2.0以上

2. 高エンゲージメント率
   - 平均エンゲージメント率5%以上
   - （エンゲージメント数/フォロワー数）

3. 公式認証
   - verified_badge = True
   - または公式関係者バッジ保有

4. 高拡散力
   - 投稿の平均リーチ数が上位5%
   - または月間総RT数が上位5%
```

### 3.3 一般層
- コア層・インフルエンサー層以外のユーザー
- さらに以下に細分化:
  - アクティブ層（週1回以上投稿）
  - カジュアル層（月1-4回投稿）
  - ROM専層（投稿なし、エンゲージメントのみ）

---

## 4. 主要分析項目

### 4.1 時系列分析

#### 4.1.1 投稿時間帯分析
```python
時間帯区分:
- 早朝: 5:00-7:59
- 朝: 8:00-11:59
- 昼: 12:00-14:59
- 夕方: 15:00-17:59
- 夜: 18:00-21:59
- 深夜: 22:00-24:59
- 未明: 1:00-4:59

分析視点:
- グループ別の活発時間帯
- 個人別の投稿ピーク時間
- ファンダム別の生活パターン
- 平日/休日の違い
```

#### 4.1.2 イベント連動分析
- ライブ・配信前後の投稿量変化
- 新曲リリース時の反応
- TV出演時のバズ分析
- 記念日（誕生日等）の特殊パターン

### 4.2 コンテンツ分析

#### 4.2.1 ワードクラウド生成
```python
対象別ワードクラウド:
1. グループ別頻出ワード
2. 個人別特徴的ワード
3. 時期別トレンドワード
4. 感情別ワード（ポジ/ネガ）
5. ハッシュタグクラウド
```

#### 4.2.2 トピックモデリング
```python
手法:
- LDA（Latent Dirichlet Allocation）
- BERTopic（最新の埋め込みベース）
- NMF（Non-negative Matrix Factorization）

トピック数: 10-20（自動最適化）
グループ別主要トピック比較
```

#### 4.2.3 感情分析
```python
分類:
- ポジティブ（応援、賞賛、愛情表現）
- ネガティブ（批判、不満、心配）
- ニュートラル（情報共有、事実報告）

感情スコア算出:
- VADER感情分析
- 日本語BERT感情分類モデル
- カスタム辞書による補正
```

### 4.3 エンゲージメント分析

#### 4.3.1 基本指標
```python
エンゲージメント指標:
- 平均いいね数
- 平均RT数
- 平均引用数
- 平均リプライ数
- エンゲージメント率（総エンゲージメント/インプレッション）
```

#### 4.3.2 バイラルスコア
```python
バイラルスコア = (いいね + RT×2 + 引用×3) / フォロワー数

バイラル判定:
- スコア > 1.0: 高バイラル
- スコア > 0.5: 中バイラル
- スコア > 0.1: 低バイラル
```

### 4.4 ネットワーク分析

#### 4.4.1 ユーザー間ネットワーク
- メンション/リプライネットワーク
- RT/引用ネットワーク
- コミュニティ検出（Louvainアルゴリズム）

#### 4.4.2 クロスファンダム分析
```python
クロスファン指標:
- 複数グループへの投稿率
- グループ間の共起分析
- ファンダム移動パターン
```

---

## 5. 可視化計画

### 5.1 基本統計ダッシュボード

#### Dashboard 1: 概要
- 総投稿数推移（日次/週次）
- UU数推移
- グループ別投稿シェア（円グラフ）
- 個人別投稿ランキング（TOP20）

#### Dashboard 2: 時系列
- 24時間ヒートマップ（グループ別）
- 曜日別投稿パターン
- イベント影響分析グラフ

### 5.2 比較分析ビジュアル

#### レーダーチャート
```python
軸項目:
1. 投稿量
2. UU数
3. エンゲージメント率
4. コア層比率
5. インフルエンサー比率
6. 投稿時間分散度
7. 感情ポジティブ率
8. バイラルスコア
```

#### 散布図マトリックス
- X軸: コア層比率
- Y軸: インフルエンサー比率
- バブルサイズ: 総投稿量
- 色: グループ/個人カテゴリ

### 5.3 テキスト分析ビジュアル

#### ワードクラウド集
- 30種類以上のワードクラウド
- インタラクティブ版（クリックで詳細表示）
- アニメーション版（時系列変化）

#### トピック分布
- サンキーダイアグラム
- 積み上げ面グラフ（時系列）
- トピック相関ネットワーク

### 5.4 ネットワークグラフ
- Force-directed layout
- Community detection色分け
- ノードサイズ: 影響力
- エッジ太さ: 関係強度

---

## 6. 実装計画

### Phase 1: データ収集と前処理（3時間）
```python
タスク:
1. 全テーブルからのデータ取得
   - UNION ALLによる統合クエリ
   - テーブル別メタデータ付与

2. データクレンジング
   - 重複除去
   - 欠損値処理
   - 外れ値検出

3. マッピングテーブル作成
   - user_id → グループ/個人対応表
   - keyword → カテゴリ分類表

4. 初期集計
   - 基本統計量算出
   - データ品質チェック
```

### Phase 2: 基礎統計分析（3時間）
```python
タスク:
1. 時系列集計
   - 日次/時間別集計
   - 移動平均算出
   - 季節性分解

2. ユーザー分析
   - セグメント分類
   - コア層判定
   - インフルエンサー特定

3. エンゲージメント計算
   - 各種指標算出
   - 相関分析
   - 回帰分析
```

### Phase 3: テキストマイニング（4時間）
```python
タスク:
1. 前処理
   - 形態素解析（MeCab/Janome）
   - ストップワード除去
   - 正規化

2. 特徴抽出
   - TF-IDF算出
   - Word2Vec学習
   - N-gram抽出

3. 高度な分析
   - トピックモデリング
   - 感情分析
   - 固有表現抽出
```

### Phase 4: 比較分析（3時間）
```python
タスク:
1. グループ間比較
   - 統計的検定
   - 効果量算出
   - 多重比較補正

2. ファンダム分析
   - クラスタリング
   - 特徴量重要度
   - 判別分析

3. 時系列比較
   - DTW距離計算
   - 変化点検出
   - トレンド分析
```

### Phase 5: 可視化とレポート（3時間）
```python
タスク:
1. ダッシュボード構築
   - Marimoインタラクティブ版
   - Plotly/Altair実装
   - フィルタリング機能

2. 静的レポート
   - HTML版（30ページ以上）
   - PDF版（エグゼクティブサマリー）
   - 画像エクスポート

3. インサイト文書
   - 主要発見事項
   - 提言まとめ
   - 今後の分析課題
```

---

## 7. 成果物一覧

### 7.1 分析レポート
1. **エグゼクティブサマリー** (PDF, 5ページ)
2. **詳細分析レポート** (HTML, 30ページ以上)
3. **統計表集** (Excel/CSV)

### 7.2 ビジュアライゼーション
1. **インタラクティブダッシュボード** (Marimo)
2. **ワードクラウド集** (PNG/SVG, 30種類)
3. **グラフ・チャート集** (PNG/SVG, 50種類以上)

### 7.3 データセット
1. **クレンジング済みデータ** (Parquet)
2. **集計テーブル** (CSV)
3. **セグメント定義** (JSON)

### 7.4 コード・ドキュメント
1. **分析ノートブック** (Jupyter/Marimo)
2. **再利用可能な関数ライブラリ** (Python)
3. **分析手法解説書** (Markdown)

---

## 8. 期待される分析結果と仮説

### 8.1 時間帯仮説
- **仮説**: グループによって投稿が活発な時間帯が大きく異なる
- **検証方法**: 時間帯別投稿数のカイ二乗検定
- **期待結果**: 学生層が多いグループは夜間、社会人層は朝夕に集中

### 8.2 コンテンツ仮説
- **仮説**: ファンダムごとに独自の文化・用語・絵文字が存在
- **検証方法**: TF-IDF、特徴的N-gram抽出
- **期待結果**: グループ特有の応援フレーズ、独自ハッシュタグの発見

### 8.3 エンゲージメント仮説
- **仮説**: コア層比率が高いグループほどエンゲージメント率も高い
- **検証方法**: 相関分析、回帰分析
- **期待結果**: 正の相関（r > 0.7）

### 8.4 クロスファン仮説
- **仮説**: 20-30%のユーザーが複数グループを応援
- **検証方法**: ユーザー別投稿先分析
- **期待結果**: 特定グループ間での高い重複率

### 8.5 インフルエンサー効果仮説
- **仮説**: インフルエンサー比率が拡散力を決定
- **検証方法**: インフルエンサー投稿のカスケード分析
- **期待結果**: 上位5%のインフルエンサーが50%以上の拡散に寄与

---

## 9. リスクと対策

### 9.1 データ品質リスク
- **リスク**: ボット、スパムアカウントの混入
- **対策**: 異常検知アルゴリズム、手動サンプリングチェック

### 9.2 計算リソースリスク
- **リスク**: 大規模データ処理の遅延
- **対策**: BigQuery内での前処理、サンプリング分析

### 9.3 解釈リスク
- **リスク**: 相関と因果の混同
- **対策**: 複数手法での検証、専門家レビュー

---

## 10. 今後の発展可能性

### 10.1 リアルタイム分析
- ストリーミングデータ処理
- 異常検知アラート
- トレンド予測

### 10.2 予測モデリング
- 次回投稿時間予測
- バズ予測モデル
- ファン離脱予測

### 10.3 レコメンデーション
- コンテンツ最適化提案
- 投稿時間最適化
- ハッシュタグ推薦

---

## 付録: 技術スタック

### 言語・フレームワーク
- Python 3.11+
- Marimo（インタラクティブノートブック）
- Pandas, Polars（データ処理）
- Scikit-learn（機械学習）

### 可視化
- Plotly（インタラクティブグラフ）
- Altair（宣言的可視化）
- Matplotlib/Seaborn（静的グラフ）
- WordCloud（ワードクラウド）
- NetworkX（ネットワーク分析）

### テキスト処理
- MeCab/Janome（形態素解析）
- spaCy（自然言語処理）
- Transformers（BERT等）
- gensim（トピックモデリング）

### データストレージ
- BigQuery（ソースデータ）
- Parquet（中間データ）
- DuckDB（ローカル分析）

---

*本計画書は2025年11月18日作成*
*対象期間: 2025年10月-11月のデータ*
*総工数見積もり: 約16-20時間*
