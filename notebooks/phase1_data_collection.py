"""Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†ã¨å‰å‡¦ç†"""

import marimo

__generated_with = "0.10.14"
app = marimo.App(width="medium")


@app.cell
def __():
    import marimo as mo
    import os
    import sys
    from pathlib import Path
    import pandas as pd
    from datetime import datetime

    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
    AGENT_NAME = os.getenv("AGENT_NAME", "phase1_data_collection")
    REPORTS_DIR = Path(os.getenv("REPORTS_DIR", "reports/comprehensive_analysis"))
    AGENT_PORT = os.getenv("AGENT_PORT", "unknown")

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)
    DATA_DIR = REPORTS_DIR / "data"
    DATA_DIR.mkdir(exist_ok=True)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
    project_root = Path.cwd().parent if Path.cwd().name == "notebooks" else Path.cwd()
    if str(project_root / "src") not in sys.path:
        sys.path.insert(0, str(project_root / "src"))

    mo.md(
        f"""
        # ğŸ“¥ Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†ã¨å‰å‡¦ç†
        
        **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå**: {AGENT_NAME}  
        **ãƒãƒ¼ãƒˆ**: {AGENT_PORT}  
        **ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ**: `{REPORTS_DIR}`
        
        ---
        
        ## ğŸ¯ ç›®çš„
        
        1. BigQueryã‹ã‚‰å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        2. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨çµ±åˆ
        3. ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        4. åŸºæœ¬çµ±è¨ˆé‡ã®ç®—å‡º
        """
    )
    return (
        AGENT_NAME,
        AGENT_PORT,
        DATA_DIR,
        Path,
        REPORTS_DIR,
        datetime,
        mo,
        os,
        pd,
        project_root,
        sys,
    )


@app.cell
def __(mo, pd, project_root):
    from ai_data_lab.connectors.bigquery import BigQueryConnector

    # BigQueryæ¥ç¶š
    bq = BigQueryConnector(project_id="yoake-dev-analysis")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
    dataset_id = "dev_yoake_posts"

    tables_query = f"""
    SELECT table_name
    FROM `{bq.project_id}.{dataset_id}.INFORMATION_SCHEMA.TABLES`
    WHERE table_type = 'BASE TABLE'
    ORDER BY table_name
    """

    try:
        tables_df = bq.query_to_dataframe(tables_query)
        table_list = tables_df["table_name"].tolist()
        
        mo.md(
            f"""
            ## ğŸ“Š æ¤œå‡ºã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«
            
            ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ `{dataset_id}` å†…ã« **{len(table_list)}** å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚
            """
        )
    except Exception as e:
        table_list = []
        mo.md(f"âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—: {e}")

    return BigQueryConnector, bq, dataset_id, table_list, tables_df, tables_query


@app.cell
def __(mo, table_list):
    # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ†é¡
    group_tables = []
    individual_tables = []

    # ã‚°ãƒ«ãƒ¼ãƒ—åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    group_keywords = [
        "FRUITS",
        "ZIPPER",
        "CUTIE",
        "STREET",
        "CANDY",
        "TUNE",
        "=LOVE",
        "ä¹ƒæœ¨å‚",
        "æ«»å‚",
        "æ—¥å‘å‚",
        "æ¨ã—ã®å­",
    ]

    for _table in table_list:
        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‹å€‹äººãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚’åˆ¤å®š
        _is_group = any(keyword.lower() in _table.lower() for keyword in group_keywords)
        if _is_group:
            group_tables.append(_table)
        else:
            individual_tables.append(_table)

    mo.md(
        f"""
        ### ãƒ†ãƒ¼ãƒ–ãƒ«åˆ†é¡çµæœ
        
        - **ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«**: {len(group_tables)} å€‹
        - **å€‹äººãƒ†ãƒ¼ãƒ–ãƒ«**: {len(individual_tables)} å€‹
        
        #### ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
        {mo.md("\\n".join([f"- `{t}`" for t in group_tables[:10]]))}
        
        #### å€‹äººãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ï¼ˆæœ€åˆã®10ä»¶ï¼‰
        {mo.md("\\n".join([f"- `{t}`" for t in individual_tables[:10]]))}
        """
    )
    return group_keywords, group_tables, individual_tables


@app.cell
def __(DATA_DIR, bq, dataset_id, group_tables, individual_tables, mo, pd):
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå„ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰1000ä»¶ãšã¤ï¼‰
    sample_size = 1000

    def fetch_table_sample(table_name: str, limit: int = sample_size) -> pd.DataFrame:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        query = f"""
        SELECT *
        FROM `{bq.project_id}.{dataset_id}.{table_name}`
        LIMIT {limit}
        """
        try:
            df = bq.query_to_dataframe(query)
            df["_source_table"] = table_name
            return df
        except Exception as e:
            print(f"Error fetching {table_name}: {e}")
            return pd.DataFrame()

    # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—
    mo.md("### ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")

    all_group_samples = []
    for _tbl in group_tables[:5]:  # æœ€åˆã®5ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«
        _sample = fetch_table_sample(_tbl)
        if not _sample.empty:
            all_group_samples.append(_sample)

    all_individual_samples = []
    for _tbl2 in individual_tables[:10]:  # æœ€åˆã®10å€‹ã®å€‹äººãƒ†ãƒ¼ãƒ–ãƒ«
        _sample2 = fetch_table_sample(_tbl2)
        if not _sample2.empty:
            all_individual_samples.append(_sample2)

    # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
    if all_group_samples:
        group_data = pd.concat(all_group_samples, ignore_index=True)
        group_data.to_parquet(DATA_DIR / "group_data_sample.parquet")
    else:
        group_data = pd.DataFrame()

    if all_individual_samples:
        individual_data = pd.concat(all_individual_samples, ignore_index=True)
        individual_data.to_parquet(DATA_DIR / "individual_data_sample.parquet")
    else:
        individual_data = pd.DataFrame()

    mo.md(
        f"""
        âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†
        
        - **ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿**: {len(group_data):,} ä»¶
        - **å€‹äººãƒ‡ãƒ¼ã‚¿**: {len(individual_data):,} ä»¶
        """
    )
    return (
        all_group_samples,
        all_individual_samples,
        fetch_table_sample,
        group_data,
        individual_data,
        sample_size,
    )


@app.cell
def __(group_data, individual_data, mo, pd):
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    def data_quality_check(df: pd.DataFrame, name: str) -> dict:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ãƒã‚§ãƒƒã‚¯"""
        return {
            "ãƒ‡ãƒ¼ã‚¿å": name,
            "ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": len(df),
            "ã‚«ãƒ©ãƒ æ•°": len(df.columns),
            "é‡è¤‡æ•°": df.duplicated().sum(),
            "æ¬ æå€¤ç‡": f"{df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100:.2f}%",
            "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡": f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB",
        }

    quality_checks = []
    if not group_data.empty:
        quality_checks.append(data_quality_check(group_data, "ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿"))
    if not individual_data.empty:
        quality_checks.append(data_quality_check(individual_data, "å€‹äººãƒ‡ãƒ¼ã‚¿"))

    quality_df = pd.DataFrame(quality_checks)

    mo.md(
        f"""
        ## ğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
        
        {mo.ui.table(quality_df)}
        """
    )
    return data_quality_check, quality_checks, quality_df


@app.cell
def __(REPORTS_DIR, datetime, group_data, individual_data, mo):
    # Phase 1å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    report_content = f"""# Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†ã¨å‰å‡¦ç† å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†çµæœ

### ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿
- **ç·ä»¶æ•°**: {len(group_data):,} ä»¶
- **ã‚«ãƒ©ãƒ æ•°**: {len(group_data.columns)} å€‹
- **ä¿å­˜å…ˆ**: `data/group_data_sample.parquet`

### å€‹äººãƒ‡ãƒ¼ã‚¿
- **ç·ä»¶æ•°**: {len(individual_data):,} ä»¶
- **ã‚«ãƒ©ãƒ æ•°**: {len(individual_data.columns)} å€‹
- **ä¿å­˜å…ˆ**: `data/individual_data_sample.parquet`

## âœ… å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

Phase 1ã®ãƒ‡ãƒ¼ã‚¿åé›†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚
Phase 2 (åŸºç¤çµ±è¨ˆåˆ†æ) ã¨Phase 3 (ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°) ã‚’ä¸¦åˆ—å®Ÿè¡Œã§ãã¾ã™ã€‚

---

*æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: Phase 2 & 3 ä¸¦åˆ—èµ·å‹•*
"""

    report_path = REPORTS_DIR / "phase1_completion_report.md"
    report_path.write_text(report_content, encoding="utf-8")

    mo.md(
        f"""
        ## âœ… Phase 1 å®Œäº†
        
        å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: `{report_path}`
        
        ### æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        
        ãƒã‚¹ã‚¿ãƒ¼ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã‹ã‚‰ **Phase 2 & 3 ã‚’ä¸¦åˆ—èµ·å‹•** ã—ã¦ãã ã•ã„ã€‚
        """
    )
    return report_content, report_path


if __name__ == "__main__":
    app.run()

