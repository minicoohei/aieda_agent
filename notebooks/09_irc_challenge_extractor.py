"""æ¨ã—æ´»ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æŠ•ç¨¿æŠ½å‡º Marimo ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

## ç›®çš„
XæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä»¥ä¸‹ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å«ã‚€æŠ•ç¨¿ã‚’æŠ½å‡ºã—ã€
ä»¥ä¸‹ã®æƒ…å ±ã‚’ä¸€è¦§è¡¨ç¤ºã™ã‚‹ï¼š
- `#æ¨ã—ã¨ã“ã®å†¬ã®äºˆå®š`
- `#å†¬ã®æ¨ã—ã“ã“ãŒå°Šã„`

### æŠ½å‡ºé …ç›®
- POSTIDï¼ˆæŠ•ç¨¿IDï¼‰
- accountidï¼ˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ 
- ã„ã„ã­æ•°
- RTæ•°
- Replyæ•°

## ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: yoake-dev-analysis
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: dev_yoake_posts
- å¯¾è±¡: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®å…¨ãƒ†ãƒ¼ãƒ–ãƒ«

## èªè¨¼
Application Default Credentials (ADC) ã‚’ä½¿ç”¨
äº‹å‰ã« `gcloud auth application-default login` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„

## ä½¿ã„æ–¹
```bash
marimo edit notebooks/09_irc_challenge_extractor.py --port 4173
```
"""

import marimo

__generated_with = "0.17.8"
app = marimo.App(width="full")


@app.cell
def _():
    import marimo as mo
    import pandas as pd
    import sys
    import os
    import requests
    import time
    from pathlib import Path
    from dotenv import load_dotenv
    from tqdm import tqdm

    # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    root_dir = Path(__file__).parent.parent
    load_dotenv(root_dir / ".env")

    # GOOGLE_APPLICATION_CREDENTIALS ãŒç„¡åŠ¹ãªå€¤ã®å ´åˆã¯å‰Šé™¤
    if "GOOGLE_APPLICATION_CREDENTIALS" in os.environ:
        gac_path = os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
        if not os.path.exists(gac_path):
            del os.environ["GOOGLE_APPLICATION_CREDENTIALS"]

    # src ã‚’ PYTHONPATH ã«è¿½åŠ 
    if str(root_dir / "src") not in sys.path:
        sys.path.insert(0, str(root_dir / "src"))

    from ai_data_lab.connectors.bigquery import BigQueryConnector

    # ScrapingDog API Key
    SCRAPINGDOG_API_KEY = os.getenv("SCRAPINGDOG_API_KEY")
    return BigQueryConnector, SCRAPINGDOG_API_KEY, mo, pd, requests, time, tqdm


@app.cell
def _(mo):
    mo.md("""
    # ğŸ·ï¸ æ¨ã—æ´»ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æŠ•ç¨¿æŠ½å‡º

    `dev_yoake_posts` ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã® **å…¨ãƒ†ãƒ¼ãƒ–ãƒ«** ã‚’æ¨ªæ–­æ¤œç´¢ã—ã€
    ä»¥ä¸‹ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å«ã‚€æŠ•ç¨¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

    ## å¯¾è±¡ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
    - `#æ¨ã—ã¨ã“ã®å†¬ã®äºˆå®š`
    - `#å†¬ã®æ¨ã—ã“ã“ãŒå°Šã„`

    ## æŠ½å‡ºé …ç›®
    - POSTIDï¼ˆæŠ•ç¨¿IDï¼‰
    - accountidï¼ˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼‰
    - ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ 
    - ã„ã„ã­æ•°
    - RTæ•°
    - Replyæ•°
    """)
    return


@app.cell
def _():
    # BigQuery è¨­å®š
    PROJECT_ID = "yoake-dev-analysis"
    DATASET_ID = "dev_yoake_posts"
    HASHTAGS = [
        "#2025å¹´æ¨ã—æ´»ã‚’æŒ¯ã‚Šè¿”ã‚‹",
    ]
    return DATASET_ID, HASHTAGS, PROJECT_ID


@app.cell
def _(BigQueryConnector, DATASET_ID, PROJECT_ID, mo):
    """BigQueryã‚³ãƒã‚¯ã‚¿åˆæœŸåŒ–ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å–å¾—"""
    try:
        connector = BigQueryConnector(project_id=PROJECT_ID)
        tables = connector.list_tables(DATASET_ID, project_id=PROJECT_ID)

        table_names = [t["table_id"] for t in tables]
        mo.md(f"âœ… æ¥ç¶šæˆåŠŸ: **{len(table_names)}** ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œå‡º")
    except Exception as e:
        mo.stop(True, mo.md(f"âŒ BigQueryæ¥ç¶šã‚¨ãƒ©ãƒ¼: `{e}`"))
    return connector, table_names


@app.cell
def _(mo, table_names):
    """æ¤œå‡ºã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    table_list = "\n".join([f"- {name}" for name in table_names])
    mo.md(
        f"""
        ## ğŸ“‚ æ¤œç´¢å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§

        {table_list}
        """
    )
    return


@app.cell
def _(mo):
    """userã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªï¼ˆPrivy IDãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç‰¹å®šç”¨ï¼‰"""
    mo.md("""
    ## ğŸ”§ userã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒç¢ºèª

    BigQueryãƒ†ãƒ¼ãƒ–ãƒ«å†…ã® `user` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ§‹é€ ã‚’ç¢ºèªã—ã¾ã™ã€‚
    """)
    return


@app.cell
def _(DATASET_ID, PROJECT_ID, connector, mo, table_names):
    """userãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã—ã¦è¡¨ç¤º"""
    try:
        # æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        sample_table = table_names[0] if table_names else None
        if sample_table:
            schema = connector.get_table_schema(DATASET_ID, sample_table, project_id=PROJECT_ID)

            # userãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¢ã™
            user_fields = []
            for field in schema:
                if field["name"] == "user":
                    user_fields = field.get("fields", [])
                    break

            if user_fields:
                field_list = "\n".join([f"- `{f['name']}` ({f['field_type']})" for f in user_fields])
                schema_output = mo.md(f"""
    ### user ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è¦§

    {field_list}

    **æ³¨æ„**: `userId` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Œã°ã€ãã‚ŒãŒPrivy IDã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
                """)
            else:
                schema_output = mo.md("âš ï¸ userãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            schema_output = mo.md("âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        schema_output = mo.md(f"âŒ ã‚¹ã‚­ãƒ¼ãƒå–å¾—ã‚¨ãƒ©ãƒ¼: `{e}`")

    schema_output
    return


@app.cell
def _(DATASET_ID, HASHTAGS, PROJECT_ID, mo, table_names):
    """å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¨ªæ–­æ¤œç´¢ã™ã‚‹UNION ALLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""

    def build_union_query(project_id, dataset_id, tables, hashtags):
        """å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’UNION ALLã§çµåˆã™ã‚‹SQLã‚’ç”Ÿæˆ"""
        queries = []
        for table_name in tables:
            # è¤‡æ•°ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ORæ¡ä»¶ã§çµåˆ
            hashtag_conditions = " OR ".join(
                [f"post.xPostContent LIKE '%{tag}%'" for tag in hashtags]
            )
            # NOTE: Privy IDã¯åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ç¾åœ¨ã¯é™¤å¤–
            query = f"""
            SELECT
                '{table_name}' AS source_table,
                post.xPostId AS post_id,
                REGEXP_EXTRACT(post.xPostUrl, r'^https://x\\.com/([^/]+)/status') AS user_handle,
                user.xPostUserId AS account_id,
                user.xPostUserName AS user_name,
                post.xPostLikedCount AS like_count,
                post.xPostRepostedCount AS rt_count,
                post.xPostRepliedCount AS reply_count,
                post.xPostContent AS content,
                TIMESTAMP_SECONDS(post.xPostCreatedAt) AS created_at,
                post.xPostUrl AS post_url
            FROM `{project_id}.{dataset_id}.{table_name}`
            WHERE _PARTITIONTIME IS NOT NULL
              AND ({hashtag_conditions})
            """
            queries.append(query)

        return "\nUNION ALL\n".join(queries)

    union_sql = build_union_query(PROJECT_ID, DATASET_ID, table_names, HASHTAGS)

    # æœ€çµ‚ã‚¯ã‚¨ãƒªï¼ˆé‡è¤‡é™¤å»ä»˜ãï¼‰
    final_query = f"""
    WITH all_posts AS (
        {union_sql}
    ),
    deduplicated AS (
        SELECT
            *,
            ROW_NUMBER() OVER (PARTITION BY post_id ORDER BY created_at DESC) AS row_num
        FROM all_posts
    )
    SELECT
        source_table,
        post_id,
        user_handle,
        account_id,
        user_name,
        like_count,
        rt_count,
        reply_count,
        content,
        created_at,
        post_url
    FROM deduplicated
    WHERE row_num = 1
    ORDER BY created_at DESC
    """

    mo.md("âœ… UNION ALL ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    return (final_query,)


@app.cell
def _(mo):
    """ã‚¯ã‚¨ãƒªå®Ÿè¡Œã¨ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    mo.md("## ğŸ” ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    return


@app.cell
def _(connector, final_query, mo):
    """#IRCãƒãƒ£ãƒ¬ãƒ³ã‚¸ æŠ•ç¨¿ã‚’æŠ½å‡º"""
    try:
        df_irc = connector.query(final_query)
        result_count = len(df_irc)
        mo.md(f"âœ… æŠ½å‡ºå®Œäº†: **{result_count:,}** ä»¶ã®æŠ•ç¨¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    except Exception as e:
        mo.stop(True, mo.md(f"âŒ ã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: `{e}`"))
    return df_irc, result_count


@app.cell
def _(df_irc, mo, result_count):
    """çµæœã‚µãƒãƒªãƒ¼"""
    if result_count == 0:
        summary_md = mo.md("âš ï¸ å¯¾è±¡ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å«ã‚€æŠ•ç¨¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        unique_users = df_irc["account_id"].nunique()
        total_likes = df_irc["like_count"].sum()
        total_rts = df_irc["rt_count"].sum()
        total_replies = df_irc["reply_count"].sum()

        summary_md = mo.md(
            f"""
            ## ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼

            | é …ç›® | å€¤ |
            |------|-----|
            | ç·æŠ•ç¨¿æ•° | **{result_count:,}** ä»¶ |
            | ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•° | **{unique_users:,}** äºº |
            | ç·ã„ã„ã­æ•° | **{total_likes:,}** |
            | ç·RTæ•° | **{total_rts:,}** |
            | ç·Replyæ•° | **{total_replies:,}** |
            """
        )
    return


@app.cell
def _(mo):
    mo.md("""
    ## ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½30ä»¶ï¼‰

    æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­30ä»¶ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_irc, mo, result_count):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½30ä»¶ï¼‰"""
    if result_count > 0:
        preview_df = df_irc.head(30)
        preview_table = mo.ui.table(preview_df, selection=None)
    else:
        preview_table = mo.md("ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
    preview_table
    return


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ“‹ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆæ•´å½¢ç‰ˆï¼‰

    æŠ•ç¨¿æ—¥æ™‚ã®æ–°ã—ã„é †ã«è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_irc, mo, result_count):
    """æŠ½å‡ºçµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    if result_count > 0:
        # è¡¨ç¤ºç”¨ã‚«ãƒ©ãƒ ã‚’é¸æŠãƒ»ãƒªãƒãƒ¼ãƒ 
        display_df = df_irc[
            [
                "post_id",
                "user_handle",
                "account_id",
                "user_name",
                "like_count",
                "rt_count",
                "reply_count",
                "content",
                "created_at",
                "post_url",
            ]
        ].copy()

        display_df.columns = [
            "POSTID",
            "UserHandle",
            "AccountID",
            "ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ",
            "ã„ã„ã­",
            "RT",
            "Reply",
            "æŠ•ç¨¿å†…å®¹",
            "æŠ•ç¨¿æ—¥æ™‚",
            "URL",
        ]

        table_output = mo.ui.table(display_df, selection=None)
    else:
        table_output = mo.md("ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")

    table_output
    return


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ“ˆ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é›†è¨ˆ

    æŠ•ç¨¿æ•°ãŒå¤šã„ãƒ¦ãƒ¼ã‚¶ãƒ¼Top20
    """)
    return


@app.cell
def _(df_irc, mo, result_count):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æŠ•ç¨¿æ•°ã¨ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé›†è¨ˆ"""
    if result_count > 0:
        user_stats = (
            df_irc.groupby(["user_handle", "account_id", "user_name"])
            .agg(
                æŠ•ç¨¿æ•°=("post_id", "count"),
                ç·ã„ã„ã­=("like_count", "sum"),
                ç·RT=("rt_count", "sum"),
                ç·Reply=("reply_count", "sum"),
            )
            .reset_index()
            .sort_values("æŠ•ç¨¿æ•°", ascending=False)
        )

        user_stats.columns = [
            "UserHandle",
            "AccountID",
            "ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ",
            "æŠ•ç¨¿æ•°",
            "ç·ã„ã„ã­",
            "ç·RT",
            "ç·Reply",
        ]

        user_table = mo.ui.table(user_stats, selection=None)
    else:
        user_table = mo.md("ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
    user_table
    return


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ’¾ CSV / TSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚’CSVã¾ãŸã¯TSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_irc, mo, result_count):
    """CSV/TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³"""
    if result_count > 0:
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨DataFrame
        export_df = df_irc[
            [
                "post_id",
                "user_handle",
                "account_id",
                "user_name",
                "like_count",
                "rt_count",
                "reply_count",
                "content",
                "created_at",
                "post_url",
                "source_table",
            ]
        ].copy()

        export_df.columns = [
            "POSTID",
            "UserHandle",
            "AccountID",
            "ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ",
            "ã„ã„ã­",
            "RT",
            "Reply",
            "æŠ•ç¨¿å†…å®¹",
            "æŠ•ç¨¿æ—¥æ™‚",
            "URL",
            "ã‚½ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«",
        ]

        csv_data = export_df.to_csv(index=False)
        tsv_data = export_df.to_csv(index=False, sep="\t")

        download_btn = mo.hstack([
            mo.download(
                data=csv_data.encode("utf-8-sig"),
                filename="oshi_hashtag_posts.csv",
                label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            ),
            mo.download(
                data=tsv_data.encode("utf-8-sig"),
                filename="oshi_hashtag_posts.tsv",
                label="ğŸ“¥ TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            ),
        ], gap=1)
    else:
        download_btn = mo.md("ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
    download_btn
    return


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ‘¤ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±å–å¾—

    ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Xãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ï¼ˆãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ç­‰ï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚

    **æ³¨æ„**: APIå‘¼ã³å‡ºã—ã«ã¯ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚ã€Œå–å¾—é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
    """)
    return


@app.cell
def _(mo):
    """ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—ãƒœã‚¿ãƒ³"""
    fetch_profile_btn = mo.ui.run_button(label="ğŸ”„ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—")
    fetch_profile_btn
    return (fetch_profile_btn,)


@app.cell
def _(
    SCRAPINGDOG_API_KEY,
    df_irc,
    fetch_profile_btn,
    mo,
    pd,
    requests,
    result_count,
    time,
    tqdm,
):
    """ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—"""

    def get_x_profile(profile_id: str, api_key: str, max_retries: int = 2) -> dict:
        """ScrapingDog APIã§Xãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        url = "https://api.scrapingdog.com/x/profile"
        params = {
            "api_key": api_key,
            "profileId": profile_id,
            "parsed": "true"
        }
        for attempt in range(max_retries):
            try:
                response = requests.get(url, params=params, timeout=15)
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã¯å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤
                    print(f"Rate limited for {profile_id}, waiting...")
                    time.sleep(2)
                    continue
            except requests.exceptions.Timeout:
                print(f"Timeout for {profile_id} (attempt {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
            except Exception as e:
                print(f"Error fetching {profile_id}: {e}")
                break
        return None

    # ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆã®ã¿å®Ÿè¡Œ
    if not fetch_profile_btn.value:
        profile_result = mo.md("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")
    elif result_count == 0:
        profile_result = mo.md("âš ï¸ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    elif not SCRAPINGDOG_API_KEY:
        profile_result = mo.md("âŒ SCRAPINGDOG_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªuser_handleã‚’å–å¾—
        unique_handles = df_irc["user_handle"].dropna().unique().tolist()
        total_users = len(unique_handles)

        profiles = []
        for handle in tqdm(unique_handles, desc="ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—ä¸­", unit="user"):
            profile_data = get_x_profile(handle, SCRAPINGDOG_API_KEY)
            if profile_data:
                # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒ "user" ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã«ã‚ã‚‹å ´åˆã«å¯¾å¿œ
                user_data = profile_data.get("user", profile_data)
                profiles.append({
                    "UserHandle": handle,
                    "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°": user_data.get("followers_count", 0),
                    "ãƒ•ã‚©ãƒ­ãƒ¼æ•°": user_data.get("following_count", 0),
                    "ç·æŠ•ç¨¿æ•°": user_data.get("statuses_count", 0),
                    "Blueèªè¨¼": user_data.get("is_blue_verified", False),
                })
            else:
                profiles.append({
                    "UserHandle": handle,
                    "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°": None,
                    "ãƒ•ã‚©ãƒ­ãƒ¼æ•°": None,
                    "ç·æŠ•ç¨¿æ•°": None,
                    "Blueèªè¨¼": None,
                })
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: 0.5ç§’å¾…æ©Ÿ
            time.sleep(0.5)

        profile_df = pd.DataFrame(profiles)
        profile_df = profile_df.sort_values("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", ascending=False, na_position="last")

        profile_result = mo.vstack([
            mo.md(f"âœ… **{len(profiles)}** ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ"),
            mo.ui.table(profile_df, selection=None)
        ])

    # profile_dfãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„å ´åˆã¯Noneã‚’è¿”ã™
    if "profile_df" not in dir():
        profile_df = None

    profile_result
    return (profile_df,)


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ“¥ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«çµåˆ CSV / TSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ï¼ˆãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã€ãƒ•ã‚©ãƒ­ãƒ¼æ•°ç­‰ï¼‰ã‚’çµåˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_irc, mo, pd, profile_df, result_count):
    """ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’çµåˆã—ãŸCSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    # profile_dfãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if result_count == 0:
        merged_csv_output = mo.md("âš ï¸ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    elif profile_df is None or (isinstance(profile_df, pd.DataFrame) and profile_df.empty):
        merged_csv_output = mo.md("âš ï¸ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ãŒå–å¾—ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šã®ã€Œãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
    else:
        # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’çµåˆ
        merged_df = df_irc.merge(
            profile_df,
            left_on="user_handle",
            right_on="UserHandle",
            how="left"
        )

        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨DataFrame
        export_merged_df = merged_df[
            [
                "post_id",
                "user_handle",
                "account_id",
                "user_name",
                "like_count",
                "rt_count",
                "reply_count",
                "content",
                "created_at",
                "post_url",
                "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°",
                "ãƒ•ã‚©ãƒ­ãƒ¼æ•°",
                "ç·æŠ•ç¨¿æ•°",
                "Blueèªè¨¼",
            ]
        ].copy()

        export_merged_df.columns = [
            "POSTID",
            "UserHandle",
            "AccountID",
            "ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ",
            "ã„ã„ã­",
            "RT",
            "Reply",
            "æŠ•ç¨¿å†…å®¹",
            "æŠ•ç¨¿æ—¥æ™‚",
            "URL",
            "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°",
            "ãƒ•ã‚©ãƒ­ãƒ¼æ•°",
            "ç·æŠ•ç¨¿æ•°",
            "Blueèªè¨¼",
        ]

        csv_merged_data = export_merged_df.to_csv(index=False)
        tsv_merged_data = export_merged_df.to_csv(index=False, sep="\t")

        merged_csv_output = mo.vstack([
            mo.md(f"âœ… **{len(export_merged_df):,}** ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¾ã—ãŸ"),
            mo.hstack([
                mo.download(
                    data=csv_merged_data.encode("utf-8-sig"),
                    filename="oshi_hashtag_posts_with_profile.csv",
                    label="ğŸ“¥ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«çµåˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                ),
                mo.download(
                    data=tsv_merged_data.encode("utf-8-sig"),
                    filename="oshi_hashtag_posts_with_profile.tsv",
                    label="ğŸ“¥ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«çµåˆTSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                ),
            ], gap=1),
            mo.md("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½10ä»¶ï¼‰"),
            mo.ui.table(export_merged_df.head(10), selection=None),
        ])

    merged_csv_output
    return


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæ¤œç´¢

    AccountID / UserHandle / ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ  ã®ä¸€è¦§ã‚’æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def _(mo):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæ¤œç´¢ç”¨ã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰"""
    user_search_input = mo.ui.text(
        value="",
        label="ğŸ” æ¤œç´¢ï¼ˆAccountID / UserHandle / ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ã§æ¤œç´¢ï¼‰",
        placeholder="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›...",
        full_width=True,
    )
    user_search_input
    return (user_search_input,)


@app.cell
def _(df_irc, mo, result_count, user_search_input):
    """ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’æ¤œç´¢å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã§è¡¨ç¤º"""
    if result_count == 0:
        user_lookup_output = mo.md("âš ï¸ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        user_lookup_df = None
    else:
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’ä½œæˆï¼ˆé‡è¤‡é™¤å»ï¼‰
        user_lookup_df = (
            df_irc[["account_id", "user_handle", "user_name"]]
            .drop_duplicates()
            .reset_index(drop=True)
        )

        # ã‚«ãƒ©ãƒ åã‚’ãƒªãƒãƒ¼ãƒ 
        user_lookup_df.columns = ["AccountID", "UserHandle", "ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ "]

        # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        search_term = user_search_input.value.strip().lower()
        if search_term:
            mask = (
                user_lookup_df["AccountID"].astype(str).str.lower().str.contains(search_term, na=False) |
                user_lookup_df["UserHandle"].astype(str).str.lower().str.contains(search_term, na=False) |
                user_lookup_df["ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ "].astype(str).str.lower().str.contains(search_term, na=False)
            )
            filtered_df = user_lookup_df[mask]
        else:
            filtered_df = user_lookup_df

        user_lookup_output = mo.vstack([
            mo.md(f"### ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ï¼ˆ{len(filtered_df):,} / {len(user_lookup_df):,} ä»¶ï¼‰"),
            mo.ui.table(filtered_df, selection=None, page_size=50),
        ])

    user_lookup_output
    return (user_lookup_df,)


@app.cell
def _(mo):
    mo.md("""
    ---
    ## ğŸ’¾ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¸€è¦§ CSV / TSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¸€è¦§ï¼ˆAccountID / UserHandle / ãƒ¦ãƒ¼ã‚¶ãƒãƒ¼ãƒ ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def _(mo, user_lookup_df):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¸€è¦§ã®CSV/TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³"""
    if user_lookup_df is None or len(user_lookup_df) == 0:
        user_download_btn = mo.md("ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
    else:
        csv_user_data = user_lookup_df.to_csv(index=False)
        tsv_user_data = user_lookup_df.to_csv(index=False, sep="\t")

        user_download_btn = mo.hstack([
            mo.download(
                data=csv_user_data.encode("utf-8-sig"),
                filename="user_id_lookup.csv",
                label="ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¸€è¦§CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            ),
            mo.download(
                data=tsv_user_data.encode("utf-8-sig"),
                filename="user_id_lookup.tsv",
                label="ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¸€è¦§TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            ),
        ], gap=1)

    user_download_btn
    return


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
